{
 "metadata": {
  "name": "",
  "signature": "sha256:0aade6a95e70a61ddfc5e6c6d46279720c8283983008cc63f5d0468f5e4ce27c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "import scipy.stats as st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse import csc_matrix \n",
      "from sparsesvd import sparsesvd "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Latent Semantic Analysis (LSA) is a method for reducing the dimnesionality of documents treated as a bag of words. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 points)**.  Calculating pairwise distance matrices.\n",
      "\n",
      "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
      "\n",
      "```python\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "```\n",
      "\n",
      "we want to find the new matrix\n",
      "\n",
      "````python\n",
      "D = np.array([[distance([1,2,3], [1,2,3]), distance([1,2,3], [4,5,6])],\n",
      "              [distance([4,5,6], [1,2,3]), distance([4,5,6], [4,5,6])]])\n",
      "```\n",
      "\n",
      "where `distance` is some appropriate function of two vectors (e.g. squared Euclidean).\n",
      "\n",
      "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some abritrary distance function. Your functions should have the following signature:\n",
      "```\n",
      "def func_name(M, distance_func):\n",
      "    pass\n",
      "```\n",
      "\n",
      "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
      "1. Write the function using looping for M as a collection of row vecotrs.\n",
      "2. Write the function using looping for M as a collection of column vectors.\n",
      "3. Wrtie the function using broadcasting for M as a colleciton of row vectors.\n",
      "4. Write the function using broadcasting for M as a colleciton of column vecotrs. \n",
      "\n",
      "For 3 and 4, try to avoid using transposition. Check that all four funcitons give the same result when applied to the given matrix $M$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "def squared_euclidean_norm(u, axis=-1):\n",
      "    return (u**2).sum(axis)\n",
      "\n",
      "def euclidean_norm(u, axis=-1):\n",
      "    return np.sqrt(squared_euclidean_norm(u, axis))\n",
      "\n",
      "def squared_euclidean_dist(u, v, axis=-1):\n",
      "    \"\"\"Returns squared Euclidean distance between two vectors.\"\"\"\n",
      "    return squared_euclidean_norm(u -v)\n",
      "\n",
      "def euclidean_dist(u, v, axis=-1):\n",
      "    \"\"\"Return Euclidean distacne between two vectors.\"\"\"\n",
      "    return np.sqrt(squared_euclidean_dist(u, v, axis))\n",
      "    \n",
      "def cosine_dist(u, v, axis=-1):\n",
      "    \"\"\"Returns cosine of angle betwwen two vectors.\"\"\"\n",
      "    # return 1 - np.dot(u, v)/(la.norm(u)*la.norm(v))\n",
      "    return 1 - (u * v).sum(axis)/(euclidean_norm(u, axis) * euclidean_norm(v, axis))\n",
      "\n",
      "def loop_row_pdist(M, f):\n",
      "    \"\"\"REturns pairwise-distance matrix assuming M consists of row vectors..\"\"\"\n",
      "    nrows, ncols = M.shape\n",
      "    return np.array([[f(M[u,:], M[v,:]) for u in range(nrows)] \n",
      "                                        for v in range(nrows)])\n",
      "\n",
      "def loop_col_pdist(M, f):\n",
      "    \"\"\"REturns pairwise-distance matrix assuming M consists of column vectors..\"\"\"\n",
      "    nrows, ncols = M.shape\n",
      "    return np.array([[f(M[:,u], M[:,v]) for u in range(ncols)] \n",
      "                                        for v in range(ncols)])\n",
      "\n",
      "def broadcast_row_pdist(M, f):\n",
      "    \"\"\"REturns pairwise-distance matrix assuming M consists of row vectors..\"\"\"\n",
      "    return f(M[None,:,:], M[:,None,:])\n",
      "\n",
      "def broadcast_col_pdist(M, f):\n",
      "    \"\"\"REturns pairwise-distance matrix assuming M consists of column vectors..\"\"\"\n",
      "    return f(M[:,None,:], M[:,:,None], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "\n",
      "dist = cosine_dist\n",
      "\n",
      "print loop_row_pdist(M, dist), '\\n'\n",
      "print broadcast_row_pdist(M, dist), '\\n'\n",
      "print loop_col_pdist(M, dist), '\\n'\n",
      "print broadcast_col_pdist(M, dist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.000  0.025]\n",
        " [ 0.025  0.000]] \n",
        "\n",
        "[[ 0.000  0.025]\n",
        " [ 0.025  0.000]] \n",
        "\n",
        "[[ 0.000  0.009  0.024]\n",
        " [ 0.009 -0.000  0.003]\n",
        " [ 0.024  0.003  0.000]] \n",
        "\n",
        "[[ 0.000  0.009  0.024]\n",
        " [ 0.009 -0.000  0.003]\n",
        " [ 0.024  0.003  0.000]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each fucntion should take a single argument `docs`, which is a dictionary of (key=identifier, value=dcoument text) pairs, and return appropriately sized array. Convert '-' to ' ' (space), remove punctuation, covert text to lowercase and split on whitepsace to genrate a collection of terms from the dcoument text.\n",
      "\n",
      "- tf = the number of occurrences of term i in document j\n",
      "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term i occurs.\n",
      "\n",
      "Print the table of tf-idf values for the follwoing document collection\n",
      "\n",
      "```\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tf(doc):\n",
      "    \"\"\"Returns the number of times each term occurs in a dcoument.\n",
      "    We preprocess the document to strip punctuation and convert to lowercase.\n",
      "    Terms are found by splitting on whitespace.\"\"\"\n",
      "    from collections import Counter\n",
      "    from string import punctuation\n",
      "\n",
      "    terms = doc.lower().replace('-', ' ').translate(None, punctuation).split()\n",
      "    return Counter(terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tfs(docs):\n",
      "    \"\"\"Create a term freqeuncy dataframe from a dictionary of documents.\"\"\"\n",
      "    from operator import add\n",
      "\n",
      "    df = pd.DataFrame({k: tf(v) for k, v in docs.iteritems()}).fillna(0)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def idf(docs):\n",
      "    \"\"\"Find inverse document frequecny series from a dictionry of doucmnets.\"\"\"\n",
      "    term_freq = tfs(docs)\n",
      "    num_docs = len(docs)\n",
      "    doc_freq = (term_freq > 0).sum(axis=1)\n",
      "    return np.log(num_docs/(1 + doc_freq))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tf_idf(docs):\n",
      "    \"\"\"Return the product of the term-frequency and inverse document freqeucny.\"\"\"\n",
      "    return tfs(docs).mul(idf(docs), axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "\n",
      "tf_idf(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>s1</th>\n",
        "      <th>s2</th>\n",
        "      <th>s3</th>\n",
        "      <th>s4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 2.772589</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>-0.223144</td>\n",
        "      <td>-0.223144</td>\n",
        "      <td>-0.669431</td>\n",
        "      <td>-1.115718</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                s1        s2        s3        s4\n",
        "brown     0.287682  0.287682  0.000000  0.000000\n",
        "dog       0.000000  0.000000  0.287682  0.287682\n",
        "elephant  0.000000  0.000000  0.287682  0.287682\n",
        "fox       0.287682  0.287682  0.000000  0.000000\n",
        "jumps     0.000000  2.772589  0.000000  0.000000\n",
        "lazy      0.000000  0.000000  0.693147  0.000000\n",
        "lion      0.000000  0.000000  0.000000  0.693147\n",
        "over      0.000000  0.693147  0.000000  0.000000\n",
        "peacock   0.000000  0.000000  0.000000  0.693147\n",
        "quick     0.693147  0.000000  0.000000  0.000000\n",
        "the      -0.223144 -0.223144 -0.669431 -1.115718\n",
        "tiger     0.000000  0.000000  0.000000  0.693147"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 points)**. \n",
      "\n",
      "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition.\n",
      "\n",
      "2. Apply the function you just wrote to the following term-frequency matrix for a set of 9 documents using k=2 and print the reconstructed matrix $M'$.\n",
      "```\n",
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "```\n",
      "\n",
      "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do teh calculations). Consider the fist 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlaiton for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "def svd_projection(M, k):\n",
      "    \"\"\"Returns the matrix M reconstructed using only k singluar values\"\"\"\n",
      "    U, s, V = la.svd(M, full_matrices=False)\n",
      "    s[k:] = 0\n",
      "    M_ = U.dot(np.diag(s).dot(V))\n",
      "    \n",
      "    try:\n",
      "        return pd.DataFrame(M_, index=M.index, columns=M.columns)\n",
      "    except AttributeError:\n",
      "        return M_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "    [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 1, 1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Md = svd_projection(M, 2)\n",
      "Md"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([[ 0.162,  0.400,  0.379,  0.468,  0.176, -0.053, -0.115, -0.159,\n",
        "        -0.092],\n",
        "       [ 0.141,  0.370,  0.329,  0.400,  0.165, -0.033, -0.071, -0.097,\n",
        "        -0.043],\n",
        "       [ 0.152,  0.505,  0.358,  0.410,  0.236,  0.024,  0.060,  0.087,\n",
        "         0.124],\n",
        "       [ 0.258,  0.841,  0.606,  0.697,  0.392,  0.033,  0.083,  0.122,\n",
        "         0.187],\n",
        "       [ 0.449,  1.234,  1.051,  1.266,  0.556, -0.074, -0.155, -0.210,\n",
        "        -0.049],\n",
        "       [ 0.160,  0.582,  0.375,  0.417,  0.277,  0.056,  0.132,  0.189,\n",
        "         0.217],\n",
        "       [ 0.160,  0.582,  0.375,  0.417,  0.277,  0.056,  0.132,  0.189,\n",
        "         0.217],\n",
        "       [ 0.218,  0.550,  0.511,  0.628,  0.243, -0.065, -0.143, -0.197,\n",
        "        -0.108],\n",
        "       [ 0.097,  0.532,  0.230,  0.212,  0.267,  0.137,  0.315,  0.444,\n",
        "         0.425],\n",
        "       [-0.061,  0.232, -0.139, -0.266,  0.145,  0.240,  0.546,  0.767,\n",
        "         0.664],\n",
        "       [-0.065,  0.335, -0.146, -0.301,  0.203,  0.306,  0.695,  0.977,\n",
        "         0.849],\n",
        "       [-0.043,  0.254, -0.097, -0.208,  0.152,  0.221,  0.503,  0.707,\n",
        "         0.616]])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rho, pval = st.spearmanr(Md)\n",
      "rho"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[ 1.000,  0.846,  1.000,  1.000,  0.718, -0.837, -0.837, -0.837,\n",
        "        -0.802],\n",
        "       [ 0.846,  1.000,  0.846,  0.846,  0.970, -0.557, -0.557, -0.557,\n",
        "        -0.480],\n",
        "       [ 1.000,  0.846,  1.000,  1.000,  0.718, -0.837, -0.837, -0.837,\n",
        "        -0.802],\n",
        "       [ 1.000,  0.846,  1.000,  1.000,  0.718, -0.837, -0.837, -0.837,\n",
        "        -0.802],\n",
        "       [ 0.718,  0.970,  0.718,  0.718,  1.000, -0.385, -0.385, -0.385,\n",
        "        -0.294],\n",
        "       [-0.837, -0.557, -0.837, -0.837, -0.385,  1.000,  1.000,  1.000,\n",
        "         0.979],\n",
        "       [-0.837, -0.557, -0.837, -0.837, -0.385,  1.000,  1.000,  1.000,\n",
        "         0.979],\n",
        "       [-0.837, -0.557, -0.837, -0.837, -0.385,  1.000,  1.000,  1.000,\n",
        "         0.979],\n",
        "       [-0.802, -0.480, -0.802, -0.802, -0.294,  0.979,  0.979,  0.979,\n",
        "         1.000]])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# G1/G1, G2/G2 and G1/G2 average correlation\n",
      "\n",
      "np.mean(rho[:5, :5][np.tril_indices_from(rho[:5, :5], 1)]), \\\n",
      "np.mean(rho[5:, 5:][np.tril_indices_from(rho[5:, 5:], 1)]), \\\n",
      "rho[5:, :5].mean() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(0.8984, 0.9935, -0.6769)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 points)**. Clustering with LSA\n",
      "\n",
      "1. Starting from the books b01.txt to b18.txt, create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
      "\n",
      "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the termas and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Using $k=2$, plot the 16 document vectors in the 2-dimensonal \"concpet space\". \n",
      "**Note**: The SVD from scipy.linalg performs a full decomposition, which is too slow for such a large matrix. We only need to decompose unitl we get the first k singluar values. Please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead only for $k = 2$. You can install in the usual way with \n",
      "```\n",
      "!pip install sparsesvd\n",
      "```\n",
      "\n",
      "3. Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html) and `sparsesvd` as before.\n",
      "\n",
      "4. Determine how similar each of the origianl 16 documents in to the new document `mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggest that in order to map the new doucment to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Rank the 16 document vectors with respect to  $q$ using the cosine distance.\n",
      "\n",
      "5. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "docs = {f: open(f).read() for f in glob.glob('b??.txt')}\n",
      "df = tf_idf(docs)\n",
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "(34455, 18)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Takes too long and too much memory\n",
      "# use sparse version instead\n",
      "\n",
      "# %time\n",
      "# T, s, D = la.svd(df)\n",
      "# T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "k = 100\n",
      "T, s, D = sparsesvd(csc_matrix(df), k)\n",
      "x = np.diag(s).dot(D)\n",
      "c = np.repeat([0,1,2], 6)\n",
      "plt.scatter(x[0,:], x[1,:], c=c[:], s=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 1 \u00b5s, total: 4 \u00b5s\n",
        "Wall time: 7.87 \u00b5s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "<matplotlib.collections.PathCollection at 0x11c0e3990>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEECAYAAADpigmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERELFOIiIiIZQoRERGxTCEiIiKW/X/bBu4lRkF8EAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11be26590>"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.index[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "Index([u'0', u'0txt', u'0ws1710atxt', u'0ws1710txt', u'0ws1710zip', u'0ws1711txt', u'0ws3210atxt', u'0ws3210txt', u'0ws3210zip', u'0ws3211txt'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc = {'mystery': open('mystery.txt').read()}\n",
      "terms = tf_idf(doc)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "{'0': 0,\n",
        " '0txt': 0,\n",
        " '0ws1710atxt': 0,\n",
        " '0ws1710txt': 0,\n",
        " '0ws1710zip': 0,\n",
        " '0ws1711txt': 0,\n",
        " '0ws3210atxt': 0,\n",
        " '0ws3210txt': 0,\n",
        " '0ws3210zip': 0,\n",
        " '0ws3211txt': 0,\n",
        " '0ws3410atxt': 0,\n",
        " '0ws3410txt': 0,\n",
        " '0ws3410zip': 0,\n",
        " '0ws3411txt': 0,\n",
        " '0zip': 0,\n",
        " '1': 0,\n",
        " '10': 0,\n",
        " '100': 0,\n",
        " '10000': 0,\n",
        " '100000000': 0,\n",
        " '101': 0,\n",
        " '102': 0,\n",
        " '103': 0,\n",
        " '105': 0,\n",
        " '105txt': 0,\n",
        " '105zip': 0,\n",
        " '106': 0,\n",
        " '109': 0,\n",
        " '10en': 0,\n",
        " '11': 0,\n",
        " '110': 0,\n",
        " '111': 0,\n",
        " '1112': 0,\n",
        " '1112txt': 0,\n",
        " '1112zip': 0,\n",
        " '112': 0,\n",
        " '113': 0,\n",
        " '114': 0,\n",
        " '115': 0,\n",
        " '116': 0,\n",
        " '117': 0,\n",
        " '118': 0,\n",
        " '119': 0,\n",
        " '12': 0,\n",
        " '120': 0,\n",
        " '121': 0,\n",
        " '121txt': 0,\n",
        " '121zip': 0,\n",
        " '122': 0,\n",
        " '123': 0,\n",
        " '124': 0,\n",
        " '125': 0,\n",
        " '126': 0,\n",
        " '127': 0,\n",
        " '128': 0,\n",
        " '129': 0,\n",
        " '12d': 0,\n",
        " '13': 0,\n",
        " '130': 0,\n",
        " '131': 0,\n",
        " '132': 0,\n",
        " '133': 0,\n",
        " '1342': 0,\n",
        " '1342txt': 0,\n",
        " '1342zip': 0,\n",
        " '135': 0,\n",
        " '136': 0,\n",
        " '137': 0,\n",
        " '138': 0,\n",
        " '139': 0,\n",
        " '14': 0,\n",
        " '140': 0,\n",
        " '1400': 0,\n",
        " '141': 0,\n",
        " '141txt': 0,\n",
        " '141zip': 0,\n",
        " '143': 0,\n",
        " '144': 0,\n",
        " '144x144png': 0,\n",
        " '145': 0,\n",
        " '146': 0,\n",
        " '147': 0,\n",
        " '148': 0,\n",
        " '14th': 0,\n",
        " '15': 0,\n",
        " '150': 0,\n",
        " '1500': 0,\n",
        " '151': 0,\n",
        " '152': 0,\n",
        " '154': 0,\n",
        " '155': 0,\n",
        " '156': 0,\n",
        " '157': 0,\n",
        " '158': 0,\n",
        " '158txt': 0,\n",
        " '158zip': 0,\n",
        " '1595': 0,\n",
        " '15th': 0,\n",
        " '16': 0,\n",
        " '160': 0,\n",
        " '161': 0,\n",
        " '161txt': 0,\n",
        " '161zip': 0,\n",
        " '162': 0,\n",
        " '1623': 0,\n",
        " '163': 0,\n",
        " '164': 0,\n",
        " '165': 0,\n",
        " '1663': 0,\n",
        " '1669': 0,\n",
        " '167': 0,\n",
        " '1685': 0,\n",
        " '169': 0,\n",
        " '17': 0,\n",
        " '170': 0,\n",
        " '1709': 0,\n",
        " '1715': 0,\n",
        " '172': 0,\n",
        " '173': 0,\n",
        " '1733': 0,\n",
        " '1744': 0,\n",
        " '1747': 0,\n",
        " '175': 0,\n",
        " '1757': 0,\n",
        " '1760': 0,\n",
        " '1765': 0,\n",
        " '1767': 0,\n",
        " '1768': 0,\n",
        " '1773': 0,\n",
        " '1784': 0,\n",
        " '1785': 0,\n",
        " '1787': 0,\n",
        " '1789': 0,\n",
        " '179': 0,\n",
        " '1790': 0,\n",
        " '1791': 0,\n",
        " '1792': 0,\n",
        " '1797': 0,\n",
        " '17th': 0,\n",
        " '18': 0,\n",
        " '180': 0,\n",
        " '1800': 0,\n",
        " '1803': 0,\n",
        " '1806': 0,\n",
        " '1808': 0,\n",
        " '181': 0,\n",
        " '1810': 0,\n",
        " '1811': 0,\n",
        " '1814': 0,\n",
        " '1816': 0,\n",
        " '1818': 0,\n",
        " '182': 0,\n",
        " '184': 0,\n",
        " '1843': 0,\n",
        " '185': 0,\n",
        " '1850': 0,\n",
        " '186': 0,\n",
        " '1863': 0,\n",
        " '1867': 0,\n",
        " '1869': 0,\n",
        " '1887': 0,\n",
        " '189': 0,\n",
        " '18th': 0,\n",
        " '19': 0,\n",
        " '190': 0,\n",
        " '1905': 0,\n",
        " '191': 0,\n",
        " '192': 0,\n",
        " '193': 0,\n",
        " '194': 0,\n",
        " '195': 0,\n",
        " '1971': 0,\n",
        " '198': 0,\n",
        " '199': 0,\n",
        " '1990': 0,\n",
        " '1993': 0,\n",
        " '1994': 0,\n",
        " '1996': 0,\n",
        " '1997': 0,\n",
        " '1998': 0,\n",
        " '1999': 0,\n",
        " '19th': 0,\n",
        " '1a': 0,\n",
        " '1b': 0,\n",
        " '1c': 0,\n",
        " '1d': 0,\n",
        " '1dtd': 0,\n",
        " '1e': 0,\n",
        " '1e1': 0,\n",
        " '1e2': 0,\n",
        " '1e3': 0,\n",
        " '1e4': 0,\n",
        " '1e5': 0,\n",
        " '1e6': 0,\n",
        " '1e7': 0,\n",
        " '1e8': 0,\n",
        " '1e9': 0,\n",
        " '1em': 0,\n",
        " '1f': 0,\n",
        " '1f1': 0,\n",
        " '1f2': 0,\n",
        " '1f3': 0,\n",
        " '1f4': 0,\n",
        " '1f5': 0,\n",
        " '1f6': 0,\n",
        " '1fai': 0,\n",
        " '1fairy': 0,\n",
        " '1gent': 0,\n",
        " '1murth': 0,\n",
        " '1sen': 0,\n",
        " '1st': 0,\n",
        " '2': 0,\n",
        " '20': 0,\n",
        " '200': 0,\n",
        " '2000': 0,\n",
        " '2001': 0,\n",
        " '2004': 0,\n",
        " '2007': 0,\n",
        " '2008': 0,\n",
        " '2009': 0,\n",
        " '201': 0,\n",
        " '2010': 0,\n",
        " '2012': 0,\n",
        " '2013': 0,\n",
        " '202': 0,\n",
        " '205': 0,\n",
        " '206': 0,\n",
        " '208': 0,\n",
        " '209': 0,\n",
        " '21': 0,\n",
        " '210': 0,\n",
        " '211': 0,\n",
        " '212': 0,\n",
        " '213': 0,\n",
        " '215': 0,\n",
        " '216': 0,\n",
        " '218': 0,\n",
        " '22': 0,\n",
        " '220': 0,\n",
        " '221': 0,\n",
        " '222': 0,\n",
        " '2242': 0,\n",
        " '225': 0,\n",
        " '226': 0,\n",
        " '2264': 0,\n",
        " '2267': 0,\n",
        " '227': 0,\n",
        " '229': 0,\n",
        " '22nd': 0,\n",
        " '23': 0,\n",
        " '230': 0,\n",
        " '23041': 0,\n",
        " '23042': 0,\n",
        " '231': 0,\n",
        " '234': 0,\n",
        " '235': 0,\n",
        " '236': 0,\n",
        " '239': 0,\n",
        " '23l': 0,\n",
        " '23rd': 0,\n",
        " '24': 0,\n",
        " '240': 0,\n",
        " '241': 0,\n",
        " '242': 0,\n",
        " '243': 0,\n",
        " '244': 0,\n",
        " '245': 0,\n",
        " '246': 0,\n",
        " '247': 0,\n",
        " '248': 0,\n",
        " '249': 0,\n",
        " '24th': 0,\n",
        " '25': 0,\n",
        " '250': 0,\n",
        " '251': 0,\n",
        " '253': 0,\n",
        " '255': 0,\n",
        " '256': 0,\n",
        " '258': 0,\n",
        " '26': 0,\n",
        " '260': 0,\n",
        " '261': 0,\n",
        " '262': 0,\n",
        " '264': 0,\n",
        " '265': 0,\n",
        " '267': 0,\n",
        " '268': 0,\n",
        " '269': 0,\n",
        " '26th': 0,\n",
        " '27': 0,\n",
        " '270': 0,\n",
        " '271': 0,\n",
        " '273': 0,\n",
        " '274': 0,\n",
        " '275': 0,\n",
        " '277': 0,\n",
        " '2782': 0,\n",
        " '28': 0,\n",
        " '280': 0,\n",
        " '281': 0,\n",
        " '282': 0,\n",
        " '284': 0,\n",
        " '285': 0,\n",
        " '289': 0,\n",
        " '28th': 0,\n",
        " '29': 0,\n",
        " '290': 0,\n",
        " '295': 0,\n",
        " '298': 0,\n",
        " '299': 0,\n",
        " '29th': 0,\n",
        " '2fai': 0,\n",
        " '2fairy': 0,\n",
        " '2murth': 0,\n",
        " '2nd': 0,\n",
        " '2sena': 0,\n",
        " '3': 0,\n",
        " '30': 0,\n",
        " '300': 0,\n",
        " '300px': 0,\n",
        " '301': 0,\n",
        " '302': 0,\n",
        " '304': 0,\n",
        " '305': 0,\n",
        " '307': 0,\n",
        " '308': 0,\n",
        " '309': 0,\n",
        " '31': 0,\n",
        " '310': 0,\n",
        " '312': 0,\n",
        " '315': 0,\n",
        " '316': 0,\n",
        " '32': 0,\n",
        " '320': 0,\n",
        " '321': 0,\n",
        " '325': 0,\n",
        " '33': 0,\n",
        " '330': 0,\n",
        " '332': 0,\n",
        " '333': 0,\n",
        " '3333': 0,\n",
        " '335': 0,\n",
        " '336': 0,\n",
        " '339': 0,\n",
        " '34': 0,\n",
        " '340': 0,\n",
        " '342': 0,\n",
        " '345': 0,\n",
        " '346': 0,\n",
        " '349': 0,\n",
        " '35': 0,\n",
        " '350': 0,\n",
        " '351': 0,\n",
        " '352': 0,\n",
        " '355': 0,\n",
        " '356': 0,\n",
        " '36': 0,\n",
        " '360': 0,\n",
        " '361': 0,\n",
        " '362': 0,\n",
        " '365': 0,\n",
        " '366': 0,\n",
        " '37': 0,\n",
        " '370': 0,\n",
        " '375': 0,\n",
        " '376': 0,\n",
        " '377': 0,\n",
        " '378': 0,\n",
        " '38': 0,\n",
        " '380': 0,\n",
        " '381': 0,\n",
        " '383': 0,\n",
        " '385': 0,\n",
        " '387': 0,\n",
        " '39': 0,\n",
        " '390': 0,\n",
        " '391': 0,\n",
        " '392': 0,\n",
        " '395': 0,\n",
        " '3fai': 0,\n",
        " '3rd': 0,\n",
        " '4': 0,\n",
        " '40': 0,\n",
        " '400': 0,\n",
        " '405': 0,\n",
        " '407': 0,\n",
        " '408': 0,\n",
        " '41': 0,\n",
        " '410': 0,\n",
        " '415': 0,\n",
        " '419': 0,\n",
        " '42': 0,\n",
        " '420': 0,\n",
        " '425': 0,\n",
        " '427': 0,\n",
        " '43': 0,\n",
        " '430': 0,\n",
        " '432': 0,\n",
        " '435': 0,\n",
        " '44': 0,\n",
        " '440': 0,\n",
        " '443': 0,\n",
        " '444': 0,\n",
        " '445': 0,\n",
        " '45': 0,\n",
        " '450': 0,\n",
        " '451': 0,\n",
        " '452': 0,\n",
        " '454': 0,\n",
        " '455': 0,\n",
        " '4557': 0,\n",
        " '46': 0,\n",
        " '460': 0,\n",
        " '465': 0,\n",
        " '468': 0,\n",
        " '469': 0,\n",
        " '47': 0,\n",
        " '470': 0,\n",
        " '471': 0,\n",
        " '475': 0,\n",
        " '478': 0,\n",
        " '48': 0,\n",
        " '480': 0,\n",
        " '48024': 0,\n",
        " '485': 0,\n",
        " '488': 0,\n",
        " '489': 0,\n",
        " '49': 0,\n",
        " '490': 0,\n",
        " '495': 0,\n",
        " '4s': 0,\n",
        " '5': 0,\n",
        " '50': 0,\n",
        " '500': 0,\n",
        " '5000': 0,\n",
        " '501c3': 0,\n",
        " '51': 0,\n",
        " '52': 0,\n",
        " '53': 0,\n",
        " '54': 0,\n",
        " '55': 0,\n",
        " '56': 0,\n",
        " '57': 0,\n",
        " '58': 0,\n",
        " '59': 0,\n",
        " '596': 0,\n",
        " '6': 0,\n",
        " '60': 0,\n",
        " '61': 0,\n",
        " '61825': 0,\n",
        " '62': 0,\n",
        " '6221541': 0,\n",
        " '63': 0,\n",
        " '64': 0,\n",
        " '65': 0,\n",
        " '66': 0,\n",
        " '67': 0,\n",
        " '68': 0,\n",
        " '69': 0,\n",
        " '6lfckowsaaaaajl5qwhpdhzsr7kkr0b5zl6hixw': 0,\n",
        " '7': 0,\n",
        " '70': 0,\n",
        " '7000l': 0,\n",
        " '72': 0,\n",
        " '73': 0,\n",
        " '730': 0,\n",
        " '730txt': 0,\n",
        " '730zip': 0,\n",
        " '74': 0,\n",
        " '74td': 0,\n",
        " '75': 0,\n",
        " '76': 0,\n",
        " '766': 0,\n",
        " '766txt': 0,\n",
        " '766zip': 0,\n",
        " '78': 0,\n",
        " '786': 0,\n",
        " '79': 0,\n",
        " '7th': 0,\n",
        " '8': 0,\n",
        " '80': 0,\n",
        " '801': 0,\n",
        " '809': 0,\n",
        " '81': 0,\n",
        " '82': 0,\n",
        " '83': 0,\n",
        " '84': 0,\n",
        " '84116': 0,\n",
        " '85': 0,\n",
        " '86': 0,\n",
        " '87': 0,\n",
        " '88': 0,\n",
        " '89': 0,\n",
        " '8em': 0,\n",
        " '8th': 0,\n",
        " '8txt': 0,\n",
        " '8zip': 0,\n",
        " '9': 0,\n",
        " '90': 0,\n",
        " '91': 0,\n",
        " '92': 0,\n",
        " '93': 0,\n",
        " '94': 0,\n",
        " '95': 0,\n",
        " '96': 0,\n",
        " '97': 0,\n",
        " '98': 0,\n",
        " '99': 0,\n",
        " '99712': 0,\n",
        " 'a': 0,\n",
        " 'aback': 0,\n",
        " 'abandon': 0,\n",
        " 'abandoned': 0,\n",
        " 'abandoning': 0,\n",
        " 'abandonment': 0,\n",
        " 'abase': 0,\n",
        " 'abased': 0,\n",
        " 'abasement': 0,\n",
        " 'abashed': 0,\n",
        " 'abasing': 0,\n",
        " 'abate': 0,\n",
        " 'abated': 0,\n",
        " 'abatement': 0,\n",
        " 'abates': 0,\n",
        " 'abating': 0,\n",
        " 'abbaye': 0,\n",
        " 'abbess': 0,\n",
        " 'abbey': 0,\n",
        " 'abbeyland': 0,\n",
        " 'abbeys': 0,\n",
        " 'abbots': 0,\n",
        " 'abbreviation': 0,\n",
        " 'abbreviations': 0,\n",
        " 'abdication': 0,\n",
        " 'abdys': 0,\n",
        " 'abear': 0,\n",
        " 'abed': 0,\n",
        " 'abel': 0,\n",
        " 'abels': 0,\n",
        " 'aberdeen': 0,\n",
        " 'aberration': 0,\n",
        " 'abet': 0,\n",
        " 'abets': 0,\n",
        " 'abetting': 0,\n",
        " 'abeyance': 0,\n",
        " 'abhor': 0,\n",
        " 'abhorre': 0,\n",
        " 'abhorred': 0,\n",
        " 'abhorrence': 0,\n",
        " 'abhorrent': 0,\n",
        " 'abhorring': 0,\n",
        " 'abhorr\\xe2\\x80\\x99d': 0,\n",
        " 'abhors': 0,\n",
        " 'abide': 0,\n",
        " 'abided': 0,\n",
        " 'abiding': 0,\n",
        " 'abilities': 0,\n",
        " 'ability': 0,\n",
        " 'abit': 0,\n",
        " 'abiure': 0,\n",
        " 'abject': 0,\n",
        " 'abjectly': 0,\n",
        " 'abjuration': 0,\n",
        " 'abjure': 0,\n",
        " 'ablaze': 0,\n",
        " 'able': 0,\n",
        " 'abler': 0,\n",
        " 'ablest': 0,\n",
        " 'ablution': 0,\n",
        " 'ablutions': 0,\n",
        " 'abnegating': 0,\n",
        " 'aboard': 0,\n",
        " 'aboardship': 0,\n",
        " 'abode': 0,\n",
        " 'abolished': 0,\n",
        " 'abolishing': 0,\n",
        " 'abolition': 0,\n",
        " 'abominable': 0,\n",
        " 'abominably': 0,\n",
        " 'abominate': 0,\n",
        " 'abominates': 0,\n",
        " 'aboord': 0,\n",
        " 'aboove\\xe2\\x80\\x99': 0,\n",
        " 'aboriginal': 0,\n",
        " 'abortive': 0,\n",
        " 'aboue': 0,\n",
        " 'abound': 0,\n",
        " 'abounded': 0,\n",
        " 'abounding': 0,\n",
        " 'aboundst': 0,\n",
        " 'about': 0,\n",
        " 'about\\xe2\\x80\\x94and': 0,\n",
        " 'about\\xe2\\x80\\x94\\xe2\\x80\\x99': 0,\n",
        " 'about\\xe2\\x80\\x99': 0,\n",
        " 'above': 0,\n",
        " 'abr': 0,\n",
        " 'abraham': 0,\n",
        " 'abrahams': 0,\n",
        " 'abram': 0,\n",
        " 'abreast': 0,\n",
        " 'abridge': 0,\n",
        " 'abridgement': 0,\n",
        " 'abridger': 0,\n",
        " 'abroach': 0,\n",
        " 'abroad': 0,\n",
        " 'abroad\\xe2\\x80\\x99': 0,\n",
        " 'abrupt': 0,\n",
        " 'abruptly': 0,\n",
        " 'abruptness': 0,\n",
        " 'absconded': 0,\n",
        " 'absconded\\xe2\\x80\\x94deserted': 0,\n",
        " 'absence': 0,\n",
        " 'absences': 0,\n",
        " 'absent': 0,\n",
        " 'absented': 0,\n",
        " 'absenting': 0,\n",
        " 'absolute': 0,\n",
        " 'absolutely': 0,\n",
        " 'absolvd': 0,\n",
        " 'absolve': 0,\n",
        " 'absolver': 0,\n",
        " 'absolves': 0,\n",
        " 'absolving': 0,\n",
        " 'absorb': 0,\n",
        " 'absorbed': 0,\n",
        " 'absorbing': 0,\n",
        " 'absorbingly': 0,\n",
        " 'absorption': 0,\n",
        " 'abstain': 0,\n",
        " 'abstained': 0,\n",
        " 'abstemious': 0,\n",
        " 'abstenious': 0,\n",
        " 'abstinence': 0,\n",
        " 'abstract': 0,\n",
        " 'abstracted': 0,\n",
        " 'abstractedly': 0,\n",
        " 'abstraction': 0,\n",
        " 'abstracts': 0,\n",
        " 'abstruse': 0,\n",
        " 'absurd': 0,\n",
        " 'absurdest': 0,\n",
        " 'absurdities': 0,\n",
        " 'absurdity': 0,\n",
        " 'absurdly': 0,\n",
        " 'absurd\\xe2\\x80\\x99': 0,\n",
        " 'abundance': 0,\n",
        " 'abundant': 0,\n",
        " 'abundantly': 0,\n",
        " 'abusd': 0,\n",
        " 'abuse': 0,\n",
        " 'abused': 0,\n",
        " 'abuser': 0,\n",
        " 'abuses': 0,\n",
        " 'abusing': 0,\n",
        " 'abusive': 0,\n",
        " 'abuts': 0,\n",
        " 'abutted': 0,\n",
        " 'abutting': 0,\n",
        " 'abydos': 0,\n",
        " 'abysm': 0,\n",
        " 'abyss': 0,\n",
        " 'abyssinia': 0,\n",
        " 'acacia': 0,\n",
        " 'academic': 0,\n",
        " 'acause': 0,\n",
        " 'accede': 0,\n",
        " 'acceded': 0,\n",
        " 'acceding': 0,\n",
        " 'accelerate': 0,\n",
        " 'accelerated': 0,\n",
        " 'acceleration': 0,\n",
        " 'accent': 0,\n",
        " 'accented': 0,\n",
        " 'accents': 0,\n",
        " 'accept': 0,\n",
        " 'acceptability': 0,\n",
        " 'acceptable': 0,\n",
        " 'acceptably': 0,\n",
        " 'acceptance': 0,\n",
        " 'acceptation': 0,\n",
        " 'accepted': 0,\n",
        " 'accepting': 0,\n",
        " 'accepts': 0,\n",
        " 'access': 0,\n",
        " 'accesse': 0,\n",
        " 'accessed': 0,\n",
        " 'accessible': 0,\n",
        " 'accessible\\xe2\\x80\\x99': 0,\n",
        " 'accession': 0,\n",
        " 'accessions': 0,\n",
        " 'accesskey1': 0,\n",
        " 'accesskeyhhelpbutton': 0,\n",
        " 'accesskeym': 0,\n",
        " 'accesskeys': 0,\n",
        " 'accessories': 0,\n",
        " 'accessory': 0,\n",
        " 'accident': 0,\n",
        " 'accidental': 0,\n",
        " 'accidentally': 0,\n",
        " 'accidently': 0,\n",
        " 'accidents': 0,\n",
        " 'acclamation': 0,\n",
        " 'acclamations': 0,\n",
        " 'accommodate': 0,\n",
        " 'accommodated': 0,\n",
        " 'accommodating': 0,\n",
        " 'accommodation': 0,\n",
        " 'accommodations': 0,\n",
        " 'accomodation': 0,\n",
        " 'accompanied': 0,\n",
        " 'accompaniment': 0,\n",
        " 'accompaniments': 0,\n",
        " 'accompany': 0,\n",
        " 'accompanying': 0,\n",
        " 'accompanyist': 0,\n",
        " 'accomplice': 0,\n",
        " 'accomplices': 0,\n",
        " 'accomplish': 0,\n",
        " 'accomplished': 0,\n",
        " 'accomplishes': 0,\n",
        " 'accomplishing': 0,\n",
        " 'accomplishment': 0,\n",
        " 'accomplishments': 0,\n",
        " 'accompt': 0,\n",
        " 'accomptant': 0,\n",
        " 'accord': 0,\n",
        " 'accordance': 0,\n",
        " 'accordant': 0,\n",
        " 'accorded': 0,\n",
        " 'accordin': 0,\n",
        " 'according': 0,\n",
        " 'accordingly': 0,\n",
        " 'accost': 0,\n",
        " 'accosted': 0,\n",
        " 'accoucheur': 0,\n",
        " 'account': 0,\n",
        " 'accountable': 0,\n",
        " 'accountant': 0,\n",
        " 'accounted': 0,\n",
        " 'accounth': 0,\n",
        " 'accounting': 0,\n",
        " 'accounts': 0,\n",
        " 'account\\xe2\\x80\\x94pardon': 0,\n",
        " 'account\\xe2\\x80\\x99': 0,\n",
        " 'accoutred': 0,\n",
        " 'accredited': 0,\n",
        " 'accrue': 0,\n",
        " 'accumulate': 0,\n",
        " 'accumulated': 0,\n",
        " 'accumulates': 0,\n",
        " 'accumulating': 0,\n",
        " 'accumulation': 0,\n",
        " 'accumulations': 0,\n",
        " 'accumulative': 0,\n",
        " 'accuracy': 0,\n",
        " 'accuracy\\xe2\\x80\\x94with': 0,\n",
        " 'accurate': 0,\n",
        " 'accurately': 0,\n",
        " 'accursd': 0,\n",
        " 'accursed': 0,\n",
        " 'accusation': 0,\n",
        " 'accusations': 0,\n",
        " 'accusatory': 0,\n",
        " 'accuse': 0,\n",
        " 'accused': 0,\n",
        " 'accuses': 0,\n",
        " 'accusing': 0,\n",
        " 'accust': 0,\n",
        " 'accustom': 0,\n",
        " 'accustomary': 0,\n",
        " 'accustomd': 0,\n",
        " 'accustomed': 0,\n",
        " 'accuthtomed': 0,\n",
        " 'ace': 0,\n",
        " 'acerbity': 0,\n",
        " 'ache': 0,\n",
        " 'ached': 0,\n",
        " 'acheron': 0,\n",
        " 'aches': 0,\n",
        " 'achieve': 0,\n",
        " 'achieved': 0,\n",
        " 'achievement': 0,\n",
        " 'achievements': 0,\n",
        " 'achieving': 0,\n",
        " 'aching': 0,\n",
        " 'acid': 0,\n",
        " 'acknowledge': 0,\n",
        " 'acknowledged': 0,\n",
        " 'acknowledgement': 0,\n",
        " 'acknowledgements': 0,\n",
        " 'acknowledging': 0,\n",
        " 'acknowledgment': 0,\n",
        " 'acknowledgments': 0,\n",
        " 'acknowne': 0,\n",
        " 'acorn': 0,\n",
        " 'acorne': 0,\n",
        " 'acos': 0,\n",
        " 'acoustical': 0,\n",
        " 'acoustics': 0,\n",
        " 'acquaint': 0,\n",
        " 'acquaintance': 0,\n",
        " 'acquaintances': 0,\n",
        " 'acquainted': 0,\n",
        " 'acquainting': 0,\n",
        " 'acquaints': 0,\n",
        " 'acquiesce': 0,\n",
        " 'acquiesced': 0,\n",
        " 'acquiescence': 0,\n",
        " 'acquiescing': 0,\n",
        " 'acquire': 0,\n",
        " 'acquired': 0,\n",
        " 'acquirements': 0,\n",
        " 'acquiring': 0,\n",
        " 'acquisition': 0,\n",
        " 'acquit': 0,\n",
        " 'acquits': 0,\n",
        " 'acquittal': 0,\n",
        " 'acquitted': 0,\n",
        " 'acquitting': 0,\n",
        " 'acre': 0,\n",
        " 'acres': 0,\n",
        " 'acrimony': 0,\n",
        " 'across': 0,\n",
        " 'acrostic': 0,\n",
        " 'act': 0,\n",
        " 'acte': 0,\n",
        " 'acted': 0,\n",
        " 'acting': 0,\n",
        " 'action': 0,\n",
        " 'actionable': 0,\n",
        " 'actionebookssearch': 0,\n",
        " 'actionhttpswwwpaypalcomcgi': 0,\n",
        " 'actions': 0,\n",
        " 'actions\\xe2\\x80\\x99': 0,\n",
        " 'actionwcaptchaanswer': 0,\n",
        " 'action\\xe2\\x80\\x99': 0,\n",
        " 'active': 0,\n",
        " 'actively': 0,\n",
        " 'activity': 0,\n",
        " 'actly': 0,\n",
        " 'actor': 0,\n",
        " 'actors': 0,\n",
        " 'actress': 0,\n",
        " 'actresses': 0,\n",
        " 'acts': 0,\n",
        " 'acts\\xe2\\x80\\x94he': 0,\n",
        " 'actual': 0,\n",
        " 'actuall': 0,\n",
        " 'actually': 0,\n",
        " 'actuary': 0,\n",
        " 'actuate': 0,\n",
        " 'actuated': 0,\n",
        " 'actus': 0,\n",
        " 'acute': 0,\n",
        " 'acutely': 0,\n",
        " 'acuteness': 0,\n",
        " 'acutest': 0,\n",
        " 'ad': 0,\n",
        " 'adage': 0,\n",
        " 'adair': 0,\n",
        " 'adam': 0,\n",
        " 'adamant': 0,\n",
        " 'adamantine': 0,\n",
        " 'adams': 0,\n",
        " 'adapt': 0,\n",
        " 'adaptation': 0,\n",
        " 'adapted': 0,\n",
        " 'adapting': 0,\n",
        " 'add': 0,\n",
        " 'addage': 0,\n",
        " 'adde': 0,\n",
        " 'added': 0,\n",
        " 'adder': 0,\n",
        " 'adders': 0,\n",
        " 'addicted': 0,\n",
        " 'adding': 0,\n",
        " 'addition': 0,\n",
        " 'additional': 0,\n",
        " 'additionally': 0,\n",
        " 'additions': 0,\n",
        " 'addle': 0,\n",
        " 'addled': 0,\n",
        " 'address': 0,\n",
        " 'addresse': 0,\n",
        " 'addressed': 0,\n",
        " 'addresses': 0,\n",
        " 'addressing': 0,\n",
        " 'address\\xe2\\x80\\x99': 0,\n",
        " 'addrest': 0,\n",
        " 'addreth': 0,\n",
        " 'adds': 0,\n",
        " 'adelaide': 0,\n",
        " 'adelphi': 0,\n",
        " 'adept': 0,\n",
        " 'adepts': 0,\n",
        " 'adequate': 0,\n",
        " 'adequately': 0,\n",
        " 'adhere': 0,\n",
        " 'adhered': 0,\n",
        " 'adherence': 0,\n",
        " 'adhering': 0,\n",
        " 'adieu': 0,\n",
        " 'adieus': 0,\n",
        " 'adjacent': 0,\n",
        " 'adjective': 0,\n",
        " 'adjoined': 0,\n",
        " 'adjoining': 0,\n",
        " 'adjourned': 0,\n",
        " 'adjuncts': 0,\n",
        " 'adjuration': 0,\n",
        " 'adjure': 0,\n",
        " 'adjured': 0,\n",
        " 'adjuring': 0,\n",
        " 'adjust': 0,\n",
        " 'adjusted': 0,\n",
        " 'adjusting': 0,\n",
        " 'adjustment': 0,\n",
        " 'administer': 0,\n",
        " 'administered': 0,\n",
        " 'administering': 0,\n",
        " 'administration': 0,\n",
        " 'administrative': 0,\n",
        " 'administrator': 0,\n",
        " 'admirable': 0,\n",
        " 'admirably': 0,\n",
        " 'admiral': 0,\n",
        " 'admirals': 0,\n",
        " 'admiralty': 0,\n",
        " 'admiration': 0,\n",
        " 'admird': 0,\n",
        " 'admire': 0,\n",
        " 'admired': 0,\n",
        " 'admirer': 0,\n",
        " 'admirers': 0,\n",
        " 'admires': 0,\n",
        " 'admire\\xe2\\x80\\x99': 0,\n",
        " 'admiring': 0,\n",
        " 'admiringly': 0,\n",
        " 'admissible': 0,\n",
        " 'admission': 0,\n",
        " 'admissions': 0,\n",
        " 'admit': 0,\n",
        " 'admits': 0,\n",
        " 'admittance': 0,\n",
        " 'admitted': 0,\n",
        " 'admitted\\xe2\\x80\\x99': 0,\n",
        " 'admitting': 0,\n",
        " 'admixture': 0,\n",
        " 'admonish': 0,\n",
        " 'admonished': 0,\n",
        " 'admonition': 0,\n",
        " 'admonitions': 0,\n",
        " 'admonition\\xe2\\x80\\x99': 0,\n",
        " 'admonitory': 0,\n",
        " 'ado': 0,\n",
        " 'adopt': 0,\n",
        " 'adopted': 0,\n",
        " 'adoption': 0,\n",
        " 'adorable': 0,\n",
        " 'adoration': 0,\n",
        " 'adore': 0,\n",
        " 'adored': 0,\n",
        " 'adoring': 0,\n",
        " 'adorn': 0,\n",
        " 'adorned': 0,\n",
        " 'adorning': 0,\n",
        " 'adornment': 0,\n",
        " 'adornments': 0,\n",
        " 'adr': 0,\n",
        " 'adrian': 0,\n",
        " 'adrift': 0,\n",
        " 'aduance': 0,\n",
        " 'aduantage': 0,\n",
        " 'aduantages': 0,\n",
        " 'aduersities': 0,\n",
        " 'aduice': 0,\n",
        " 'aduisd': 0,\n",
        " 'aduise': 0,\n",
        " 'adult': 0,\n",
        " 'adulterated': 0,\n",
        " 'adulteration': 0,\n",
        " 'aduocation': 0,\n",
        " 'adust': 0,\n",
        " 'advancd': 0,\n",
        " 'advance': 0,\n",
        " 'advanced': 0,\n",
        " 'advancement': 0,\n",
        " 'advances': 0,\n",
        " 'advancing': 0,\n",
        " 'advantage': 0,\n",
        " 'advantageous': 0,\n",
        " 'advantageously': 0,\n",
        " 'advantages': 0,\n",
        " 'advantages\\xe2\\x80\\x94but': 0,\n",
        " 'advantages\\xe2\\x80\\x94disadvantages': 0,\n",
        " 'advantages\\xe2\\x80\\x94so': 0,\n",
        " 'advent': 0,\n",
        " 'adventure': 0,\n",
        " 'adventurer': 0,\n",
        " 'adventurers': 0,\n",
        " ...}"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = {c: i for (i,c) in enumerate('abcde')}\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = {c: i for (i,c) in enumerate('cdefg')}\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "{'c': 0, 'd': 1, 'e': 2, 'f': 3, 'g': 4}"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "k = 300\n",
      "T, s, D = sparsesvd(csc_matrix(df), k)\n",
      "x = np.diag(s).dot(D).T\n",
      "data_dist = pdist(x, metric='cosine') # computing the distance\n",
      "data_link = linkage(data_dist) # computing the linkage\n",
      "dendrogram(data_link,labels=x.dtype.names)\n",
      "plt.xlabel('Samples')\n",
      "plt.ylabel('Distance')\n",
      "plt.suptitle('Samples clustering', fontweight='bold', fontsize=14);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEqCAYAAAD6aUxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkfD/ztstfKicsywAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x114eaee90>"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}