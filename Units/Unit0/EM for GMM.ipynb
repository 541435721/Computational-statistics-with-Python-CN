{
 "metadata": {
  "name": "",
  "signature": "sha256:e29df8afb198b601bba72564cc7e4a7ceb558cab916f6f5828d5c24e1c240684"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gaussian mixture models\n",
      "----\n",
      "\n",
      "A mixture of $k$ Gaussians has the following PDF\n",
      "\n",
      "\\begin{align}\n",
      "p(x) = \\sum_{j=1}^k \\alpha_j \\phi(x; \\mu_j, \\Sigma_j)\n",
      "\\end{align}\n",
      "\n",
      "where $\\alpha_j$ is the weight of the $j^\\text{th}$ Gaussain component and \n",
      "\n",
      "\\begin{align}\n",
      "\\phi(x; \\mu, \\Sigma) = \\frac{1}{(2 \\pi)^{d/2}|\\Sigma|^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\right)\n",
      "\\end{align}\n",
      "\n",
      "Suppose we observe $y_1, y2, \\ldots, y_n$ as a sample from a mixture of Gaussians. The log-likeihood is then\n",
      "\n",
      "\\begin{align}\n",
      "l(\\theta) = \\sum_{i=1}^n \\log \\left( \\sum_{j=1}^k \\alpha_j \\phi(y_i; \\mu_j, \\Sigma_j) \\right)\n",
      "\\end{align}\n",
      "\n",
      "where $\\theta = (\\alpha, \\mu, \\Sigma)$\n",
      "\n",
      "There is no closed form for maximizing the parameters of this log-likelihood, and it is hard to maximize directly.\n",
      "\n",
      "Using EM\n",
      "----\n",
      "\n",
      "Suppose we augment with the latent variable $z$ that indicates which of the $k$ Gaussians our observation $y$ came from. The derivation of the E and M steps are the same as for the toy example, only with more algebra.\n",
      "\n",
      "For the E-step, we have\n",
      "\n",
      "\\begin{align}\n",
      "w_j^i &= Q_i(z^i = j) \\\\\n",
      "&= p(z^i = j | y^i; \\theta) \\\\\n",
      "&= \\frac{p(y^i | z^i = j; \\mu, \\Sigma) p(z^i = j; \\alpha)}  {\\sum_{l=1}^k{p(y^i | z^i = l; \\mu, \\Sigma) p(z^i = l; \\alpha)}}  && \\text{Baye's rule} \\\\\n",
      "&= \\frac{\\phi(y^i; \\mu_j, \\Sigma_j) \\alpha_j}{\\sum_{l=1}^k \\phi(y^i; \\mu_l, \\Sigma_l) \\alpha_l}\n",
      "\\end{align}\n",
      "\n",
      "For the M-step, we have to find $\\theta = (w, \\mu, \\Sigma)$ that maximizes $Q$\n",
      "\n",
      "\\begin{align}\n",
      "\\sum_{i=1}^{m}\\sum{j=1}^{k} Q(z^i=j) \\log \\frac{p(x^i | z^i= j; \\mu, \\Sigma) p(z^i=j; \\alpha)}{Q(z^i=j)}\n",
      "\\end{align}\n",
      "\n",
      "By taking derivatives with respect to $(w, \\mu, \\Sigma)$ respectively and solving (remember to use Lagrange multipliers for the constraint that $\\sum_{j=1}^k w_j = 1$), we get\n",
      "\n",
      "\\begin{align}\n",
      "\\alpha_j &= \\frac{1}{m} \\sum_{i=1}^{m} w_j^i \\\\\n",
      "\\mu_j &= \\frac{\\sum_{i=1}^{m} w_j^i x^i}{\\sum_{i=1}^{m} w_j^i} \\\\\n",
      "\\Sigma_j &= \\frac{\\sum_{i=1}^{m} w_j^i (x^i - \\mu)(x^i - \\mu)^T}{\\sum_{i1}^{m} w_j^i}\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "%precision 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "u'%.4f'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import multivariate_normal as mvn\n",
      "\n",
      "def normalize(xs, axis=None):\n",
      "    \"\"\"Return normalized marirx so that sum of row or column (default) entries = 1.\"\"\"\n",
      "    if axis is None:\n",
      "        return xs/xs.sum()\n",
      "    elif axis==0:\n",
      "        return xs/xs.sum(0)\n",
      "    else:\n",
      "        return xs/xs.sum(1)[:, None]\n",
      "\n",
      "def mix_mvn_pdf(xs, pis, mus, sigmas):\n",
      "    return np.array([pi*mvn(mu, sigma).pdf(xs) for (pi, mu, sigma) in zip(pis, mus, sigmas)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mus = np.array([[0,4], [-2,0]])\n",
      "sigmas = np.array([[[3, 0], [0, 0.5]], [[1,0],[0,2]]])\n",
      "pis = np.array([0.6, 0.4])\n",
      "\n",
      "xs = np.array([[-2,0],[0,4], [0,3], [0,5]])\n",
      "ws = mix_mvn_pdf(xs, pis, mus, sigmas)\n",
      "ys = (xs[0] - mus[0]).reshape(2,1)\n",
      "np.dot(ys, ys.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 211,
       "text": [
        "array([[ 4,  8],\n",
        "       [ 8, 16]])"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_mus = np.array([[0,4], [-2,0]])\n",
      "_sigmas = np.array([[[3, 0], [0, 0.5]], [[1,0],[0,2]]])\n",
      "_pis = np.array([0.6, 0.4])\n",
      "m = 1000\n",
      "p = len(mus)\n",
      "xs = np.concatenate([np.random.multivariate_normal(mu, sigma, int(pi*m)) \n",
      "                    for pi, mu, sigma in zip(_pis, _mus, _sigmas)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mus = np.random.random((2,2))\n",
      "sigmas = np.array([np.eye(2)] * 2)\n",
      "pis = normalize(np.random.random(2))\n",
      "\n",
      "tol = 0.01\n",
      "max_iter = 50\n",
      "\n",
      "ll_old = 0\n",
      "for i in range(max_iter):\n",
      "    exp_A = []\n",
      "    exp_B = []\n",
      "    ll_new = 0\n",
      "\n",
      "    # E-step\n",
      "    ws = np.zeros((len(mus), m))\n",
      "    for j in range(len(mus)):\n",
      "        for k in range(m):\n",
      "            ws[j, k] = pis[j] * mvn(mus[j], sigmas[j]).pdf(xs[k])\n",
      "    ws /= ws.sum(0)\n",
      "\n",
      "    # M-step\n",
      "    pis = np.zeros(len(mus))\n",
      "    for j in range(len(mus)):\n",
      "        for k in range(m):\n",
      "            pis[j] += ws[j, k]\n",
      "    pis /= m\n",
      "\n",
      "    # mus = np.dot(ws, xs)/ws.sum()\n",
      "    mus = np.zeros((len(mus), p))\n",
      "    for j in range(len(mus)):\n",
      "        for k in range(m):\n",
      "            mus[j] += ws[j, k] * xs[k]\n",
      "        mus[j] /= ws[j, :].sum()\n",
      "\n",
      "    sigmas = np.zeros((len(mus), p, p))\n",
      "    for j in range(len(mus)):\n",
      "        for k in range(m):\n",
      "            ys = np.reshape(xs[k]- mus[j], (2,1))\n",
      "            sigmas[j] += ws[j, k] * np.dot(ys, ys.T)\n",
      "        sigmas[j] /= ws[j,:].sum()\n",
      "\n",
      "    # update complete log likelihoood \n",
      "    ll_new = 0.0\n",
      "    for k in range(m):\n",
      "        s = 0\n",
      "        for j in range(len(mus)):\n",
      "            s += pis[j] * mvn(mus[j], sigmas[j]).pdf(xs[j])\n",
      "        ll_new += np.log(s)\n",
      "    ll_new /= m\n",
      "    \n",
      "    # print distribution of z for each x and current parameter estimate\n",
      "    print \"Iteration: %d\" % (i+1), ll_new\n",
      " \n",
      "    if np.abs(ll_new - ll_old) < tol:\n",
      "        break\n",
      "    ll_old = ll_new\n",
      "\n",
      "    \n",
      "print \"pis\\n\", pis\n",
      "print \"_pis\\n\", _pis\n",
      "print \"mus\\n\", mus\n",
      "print \"_mus\\n\", _mus\n",
      "print \"sigmas\\n\", sigmas\n",
      "print \"_simgas\\n\", _sigmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 1 -5.41748148539\n",
        "Iteration: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.64852655302\n",
        "Iteration: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.69676206823\n",
        "Iteration: 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.61602802939\n",
        "Iteration: 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.50512613919\n",
        "Iteration: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.40398373014\n",
        "Iteration: 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.32230526762\n",
        "Iteration: 8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.25876900699\n",
        "Iteration: 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.20915393564\n",
        "Iteration: 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.16952990483\n",
        "Iteration: 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.13705345748\n",
        "Iteration: 12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.1100679297\n",
        "Iteration: 13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.08783762721\n",
        "Iteration: 14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.06995488157\n",
        "Iteration: 15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.05591659143\n",
        "Iteration: 16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.04508829239\n",
        "Iteration: 17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -5.03682406023\n",
        "pis\n",
        "[ 0.5999  0.4001]\n",
        "_pis\n",
        "[ 0.6  0.4]\n",
        "mus\n",
        "[[-0.0653  4.0133]\n",
        " [-2.0041  0.0185]]\n",
        "_mus\n",
        "[[ 0  4]\n",
        " [-2  0]]\n",
        "sigmas\n",
        "[[[ 3.0492  0.0938]\n",
        "  [ 0.0938  0.5486]]\n",
        "\n",
        " [[ 1.0273  0.121 ]\n",
        "  [ 0.121   2.1624]]]\n",
        "_simgas\n",
        "[[[ 3.   0. ]\n",
        "  [ 0.   0.5]]\n",
        "\n",
        " [[ 1.   0. ]\n",
        "  [ 0.   2. ]]]\n"
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}