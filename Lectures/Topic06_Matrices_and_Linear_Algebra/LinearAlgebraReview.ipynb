{
 "metadata": {
  "name": "",
  "signature": "sha256:c60d2882d61cc783f4a60d702e8b783244958e9221413ff5264bcaf934fa96c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Linear Algebra and Linear Systems"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A lot of problems in statistical computing can be described mathematically using linear algebra.  This lecture is meant to serve as a review of concepts you have covered in linear algebra courses."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simultaneous Equations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider a set of $m$ linear equations in $n$ unknowns:\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\\begin{align*}\n",
      "a_{11} x_1 + &a_{12} x_2& +& ... + &a_{1n} x_n &=& b_1\\\\\n",
      "\\vdots  && &&\\vdots &= &\\vdots\\\\\n",
      "a_{m1} x_1 + &a_{m2} x_2& +& ... + &a_{mn} x_n &=&b_m \n",
      "\\end{align*}\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "We can let:\n",
      "\n",
      "\\begin{align*}\n",
      "    A=\\left[\\begin{matrix}a_{11}&\\cdots&a_{1n}\\\\\n",
      "               \\vdots & &\\vdots\\\\\n",
      "               a_{m1}&\\cdots&a_{mn}\\end{matrix}\\right], & & \n",
      "\n",
      "x = \\left[\\begin{matrix}x_1\\\\\n",
      "               \\vdots\\\\\n",
      "               x_n\\end{matrix}\\right] & \\;\\;\\;\\;\\textrm{   and } &\n",
      "b =  \\left[\\begin{matrix}b_1\\\\\n",
      "               \\vdots\\\\\n",
      "               b_m\\end{matrix}\\right]\n",
      "\\end{align*}\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "We can let:\n",
        "\n",
        "\\begin{align*}\n",
        "    A=\\left[\\begin{matrix}a_{11}&\\cdots&a_{1n}\\\\\n",
        "               \\vdots & &\\vdots\\\\\n",
        "               a_{m1}&\\cdots&a_{mn}\\end{matrix}\\right], & & \n",
        "\n",
        "x = \\left[\\begin{matrix}x_1\\\\\n",
        "               \\vdots\\\\\n",
        "               x_n\\end{matrix}\\right] & \\;\\;\\;\\;\\textrm{   and } &\n",
        "b =  \\left[\\begin{matrix}b_1\\\\\n",
        "               \\vdots\\\\\n",
        "               b_m\\end{matrix}\\right]\n",
        "\\end{align*}\n"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x7f20d85e0390>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "And re-write the system:\n",
      "    \n",
      "$$ Ax = b$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solving the system now amounts to finding $A^{-1}$.  Of course, strictly speaking, $A^{-1}$ is defined only when $A$ is an $n\\times n$ matrix of full rank.  There are weaker forms of inverse (generalized inverses) that work in the case that $A$ is $m\\times n$.  A generalized inverse of $A$, $A^g$, is a matrix with the property:  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$A A^g A = A$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The generalized inverse is not unique.  When it exists, the Moore-Penrose inverse is useful.  It has the additional properties:\n",
      "\n",
      "$$A^g A A^g = A^g$$\n",
      "$$\\left(A A^g\\right)^t = A A^g$$\n",
      "$$\\left(A^g A\\right)^t = A^g A$$\n",
      "\n",
      "In other words, $A$ is also a generalized inverse of $A^g$, and the products $A A^g$ and $A^g A$ are symmetric."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If $A^g$ is the Moore-Penrose inverse of $A$, then \n",
      "$$x = A^g b$$\n",
      "is the shortest length least-squares solution to\n",
      "$$Ax =b$$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, lets solve a system in Python!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.set_printoptions(suppress=True)   # Suppress printing of negligibly small numbers - print as zero.\n",
      "a = np.random.randn(6, 9)\n",
      "a_pseudo_inv = np.linalg.pinv(a)\n",
      "print(np.dot(a,a_pseudo_inv))                  # We can see that a_pseudo_inv has inverted part of a.\n",
      "\n",
      "b = np.random.rand(6,1)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1. -0.  0. -0. -0.  0.]\n",
        " [ 0.  1.  0.  0.  0. -0.]\n",
        " [ 0. -0.  1. -0.  0.  0.]\n",
        " [-0. -0.  0.  1. -0.  0.]\n",
        " [-0.  0.  0. -0.  1.  0.]\n",
        " [-0.  0.  0.  0. -0.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The solution to the system $Ax=b$ is given by:\n",
      "    $$A^gb +(I - A^gA)v$$\n",
      "where $v$ is an arbitrary vector.  If $A$ is invertible, then $A^g$ is its unique inverse and $I-A^gA$ is the zero matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.dot(a_pseudo_inv,b)) \n",
      "print(np.identity(9) - np.dot(a_pseudo_inv, a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.38711309]\n",
        " [-0.31442491]\n",
        " [ 0.66029409]\n",
        " [-0.0751685 ]\n",
        " [-0.45190989]\n",
        " [ 0.26597446]\n",
        " [-0.11829717]\n",
        " [-0.2353295 ]\n",
        " [ 0.32334829]]\n",
        "[[ 0.16300068  0.04941738  0.11682394 -0.03435597 -0.01904584 -0.25152876\n",
        "   0.04311034 -0.04165154 -0.22789999]\n",
        " [ 0.04941738  0.28918131  0.19460042  0.25853562 -0.11147669  0.09495047\n",
        "   0.06234735  0.20278236 -0.17875372]\n",
        " [ 0.11682394  0.19460042  0.17969467  0.09655198 -0.0845402  -0.0855338\n",
        "   0.04460437  0.13971148 -0.22492916]\n",
        " [-0.03435597  0.25853562  0.09655198  0.61488229 -0.00597979  0.26670732\n",
        "   0.18579339 -0.21768886 -0.07989118]\n",
        " [-0.01904584 -0.11147669 -0.0845402  -0.00597979  0.06849969 -0.02414093\n",
        "   0.01589582 -0.19744794  0.063354  ]\n",
        " [-0.25152876  0.09495047 -0.0855338   0.26670732 -0.02414093  0.50112816\n",
        "  -0.01625195  0.14051147  0.28049458]\n",
        " [ 0.04311034  0.06234735  0.04460437  0.18579339  0.01589582 -0.01625195\n",
        "   0.08271626 -0.15887773 -0.0886618 ]\n",
        " [-0.04165154  0.20278236  0.13971148 -0.21768886 -0.19744794  0.14051147\n",
        "  -0.15887773  0.73719503 -0.00198708]\n",
        " [-0.22789999 -0.17875372 -0.22492916 -0.07989118  0.063354    0.28049458\n",
        "  -0.0886618  -0.00198708  0.36370191]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many techniques to solve linear systems.  Our goal is to understand the theory behind many of the built-in functions, and how they *efficiently* solve systems of equations.  In fact, finding $A^{-1}$ is often *not* the best approach to solving a system of equations.\n",
      "\n",
      "\n",
      "First, let's review some linear algebra topics:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Linear Independence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A collection of vectors $v_1,...,v_n$ is said to be *linearly independent* if\n",
      "\n",
      "$$c_1v_1 + \\cdots c_nv_n = 0$$\n",
      "$$\\iff$$\n",
      "$$c_1=\\cdots=c_n=0$$\n",
      "\n",
      "In other words, any linear combination of the vectors that results in a zero vector is trivial."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another interpretation of this is that no vector in the set may be expressed as a linear combination of the others.  In this sense, linear independence is an expression of non-redundancy in a set of vectors.\n",
      "\n",
      "\n",
      "Fact: Any linearly independent set of $n$ vectors spans an $n$-dimensional space. (I.e. the collection of all possible linear combinations is $\\mathbb{R}^n$.)  Such a set of vectors is said to be a *basis* of $\\mathbb{R}^n$.  Another term for basis is *minimal spanning set*."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Norms and Distance of Vectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that the 'norm' of a vector $v$, denoted $||v||$ is simply its length.  For a vector with components \n",
      "$$v = \\left(v_1,...,v_n\\right)$$\n",
      "the norm of $v$ is given by:\n",
      "    \n",
      "$$||v|| = \\sqrt{v_1^2+...+v_n^2}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The distance between two vectors is the length of their difference:\n",
      "    \n",
      "$$d(v,w) = ||v-w||$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Trace and Determinant of Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The trace of a matrix $A$ is the sum of its diagonal elements.  It is important for a couple of reasons:\n",
      "\n",
      "* It is an *invariant* of a matrix under change of basis (more on this later).\n",
      "* It defines a matrix norm (more on that later)\n",
      "\n",
      "The determinant of a matrix is defined to be the alternating sum of permutations of the elements of a matrix.  Let's not dwell on that though. It is important to know that the determinant of a $2\\times 2$ matrix is\n",
      "\n",
      "$$\\left|\\begin{matrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{matrix}\\right| = a_{11}a_{22} - a_{12}a_{21}$$\n",
      "\n",
      "This may be extended to an $\\times n$ matrix by minor expansion.  I will leave that for you to google.  We will be computing determinants using tools such as:\n",
      "\n",
      "``np.linalg.det(A)``\n",
      "\n",
      "What is most important about the determinant:\n",
      "\n",
      "* Like the trace, it is also invariant under change of basis\n",
      "* An $n\\times n$ matrix $A$ is invertible $\\iff$ det$(A)\\neq 0$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Column space, Row space, Rank and Kernel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let $A$ be an $m\\times n$ matrix.  We can view the columns of $A$ as vectors, say $\\textbf{a_1},...,\\textbf{a_n}$. The space of all linear combinations of the $\\textbf{a_i}$ are the *column space* of the matrix $A$.  Now, if $\\textbf{a_1},...,\\textbf{a_n}$ are *linearly independent*, then the column space is of dimension $n$.  Otherwise, the dimension of the column space is the size of the maximal set of linearly independent $\\textbf{a_i}$.  Row space is exactly analogous, but the vectors are the *rows* of $A$.\n",
      "\n",
      "The *rank* of a matrix *A* is the dimension of its column space - and - the dimension of its row space.  These are equal for any matrix.  Rank can be thought of as a measure of non-degeneracy of a system of linear equations, in that it is the *dimension of the image of the linear transformation* determined by $A$. \n",
      "\n",
      "The *kernel* of a matrix *A* is the dimension of the space mapped to zero under the linear transformation that $A$ represents. The dimension of the kernel of a linear transformation is called the *nullity*. \n",
      "\n",
      "Index theorem: For and $m\\times n$ matrix $A$, \n",
      "\n",
      "rank($A$) + nullity($A$) = $n$.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Matrices as Linear Transformations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Matrices are not just nice ways to package systems of linear equations.  In fact, they have properties that facilitate solving such systems.\n",
      "\n",
      "Let's consider: what does a matrix *do* to a vector?  Matrix multiplication has a *geometric* interpretation.  When we multiply a vector, we either rotate, reflect, dilate or some combination of those three. So multiplying by a matrix *transforms* one vector into another vector.  This is known as a *linear transformation*.\n",
      "\n",
      "Important Facts: \n",
      "\n",
      "* Any matrix defines a linear transformation\n",
      "* The matrix form of a linear transformation is NOT unique\n",
      "* We need only define a transformation by saying what it does to a *basis*\n",
      "\n",
      "Suppose we have a matrix $A$ that defines some transformation.  We can take any invertible matrix $B$ and\n",
      "\n",
      "$$BAB^{-1}$$\n",
      "\n",
      "defines the same transformation.  This operation is called a *change of basis*, because we are simply expressing the transformation with respect to a different basis.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Example:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Let $f(x)$ be the linear transformation that takes $e_1=(1,0)$ to "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Special Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some matrices have interesting properties that allow us either simplify the underlying linear system or to understand more about it. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Square Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Square matrices have the same number of columns (usually denoted $n$).  We refer to an arbitrary square matrix as and $n\\times n$ or we refer to it as a 'square matrix of dimension $n$'.  If an $n\\times n$ matrix $A$ has *full rank* (i.e. it has rank $n$), then $A$ is invertible, and its inverse is unique.  This is a situation that leads to a unique solution to a linear system."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Diagonal Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A diagonal matrix is a matrix with all entries off the diagonal equal to zero.  Strictly speaking, such a matrix should be square, but we can also consider rectangular matrices of size $m\\times n$ to be diagonal, if all entries $a_{ij}$ are zero for $i\\neq j$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Symmetric and Skew Symmetric"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A matrix $A$ is (skew) symmetric if $a_{ij} = (-)a_{ji}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Upper and Lower Triangular"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A matrix $A$ is (upper|lower) triangular if $a_{ij} = 0$ for all $i (>|<) j$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}